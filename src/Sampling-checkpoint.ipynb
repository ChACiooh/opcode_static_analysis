{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, glob\t# to set directory\n",
    "import os.path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codon mapping\n",
    "instr_code = dict()\n",
    "f = open('instrlist.txt', 'r')\n",
    "lines = f.readlines()\n",
    "for i in range(len(lines)):\n",
    "\tc = format(i+1, 'X')\t# hex\n",
    "\tinstr_code[lines[i]] = c\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def directory_mapping(d, files):\n",
    "\tfor i in range(len(files)):\n",
    "\t\tfiles[i] = d + files[i]\n",
    "\treturn files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_output(file_name, cont):\n",
    "\tKeqing = ''\n",
    "\tf = open(file_name, 'w')\n",
    "\tfor i in cont:\n",
    "\t\tKeqing = Keqing + i + ' ' + str(cont[i]) + '\\n'\n",
    "\tf.write(Keqing)\n",
    "\tf.close()\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### main action part ###\n",
    "targetdir0 = r\"./opcode/0/\"\t# ransomwares\n",
    "targetdir1 = r\"./opcode/1/\"\t# good files\n",
    "\n",
    "files0 = directory_mapping(targetdir0, os.listdir(targetdir0))\t# file name list of 0\n",
    "files1 = directory_mapping(targetdir1, os.listdir(targetdir1))\t# file name list of 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_sequence(file_name, ngram = 4):\n",
    "# generate sequences and number of them of each file\n",
    "# return : {'sequence' : cnt} of input file\n",
    "\tf = open(file_name, 'r')\n",
    "\tlines = f.readlines()\n",
    "\tl = len(lines)\n",
    "\tres = dict()\n",
    "\tif l < ngram:\n",
    "\t\treturn res\n",
    "\ti = 0\n",
    "\ttotal = 0\n",
    "\twhile i + ngram <= l:\t# n-gram sequence modeling\n",
    "\t\ta = ''\n",
    "\t\tj = i + ngram\n",
    "\t\twhile i < j:\n",
    "\t\t\ta = a + instr_code[lines[i]] + ' '\n",
    "\t\t\ti += 1\n",
    "\t\tif a not in res:\n",
    "\t\t\tres[a] = 1\n",
    "\t\telse:\n",
    "\t\t\tres[a] += 1\n",
    "\t\ttotal += 1\n",
    "\tf.close()\n",
    "\tfor i in res:\n",
    "\t\tres[i] /= total\t\t# estimate TF\n",
    "\treturn res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_analysis(file_list, ngram = 4):\n",
    "\tres = dict()\n",
    "\tfor i in file_list:\n",
    "\t\tres[i] = gen_sequence(i, ngram)\t\t# i-th file has sequences and their TF respectively\n",
    "\treturn res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct n-gram sequences and their TFs of input files\n",
    "R_sq = sequence_analysis(files0)\n",
    "N_sq = sequence_analysis(files1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def est_sequence(analyzed_file_list):\t# 해당 파일 그룹에 나타나는 시퀀스들의 idf\n",
    "\tseq_cnt = dict()\n",
    "\ttdf = dict()\n",
    "\tnum_of_files = len(analyzed_file_list)\n",
    "\tfor r in analyzed_file_list:\n",
    "\t\tnow_file = analyzed_file_list[r]\n",
    "\t\tfor s in now_file:\t# s is a sequence of each analyzed_file_list\n",
    "\t\t\tif s not in seq_cnt:\n",
    "\t\t\t\tseq_cnt[s] = 1\n",
    "\t\t\telse:\n",
    "\t\t\t\tseq_cnt[s] += 1\n",
    "\tfor d in analyzed_file_list:\n",
    "\t\tnow_file = analyzed_file_list[d]\n",
    "\t\tfor s in now_file:\n",
    "\t\t\ttf = now_file[s]\n",
    "\t\t\tif s not in tdf:\n",
    "\t\t\t\ttdf[s] = 0\n",
    "\t\t\ttdf[s] += tf * np.log(num_of_files / seq_cnt[s]) / num_of_files # estimate mean\n",
    "\treturn tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to find moderate value of threshold\n",
    "est_R_train = est_sequence(R_sq)\n",
    "est_N_train = est_sequence(N_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_print(cont, threshold = 0.0003, k = 10):\n",
    "    for i in cont:\n",
    "        if k < 1:\n",
    "            break\n",
    "        if cont[i] > threshold:\n",
    "            print(i + ' ' + str(cont[i]))\n",
    "            k -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if no option, print 10 lines in default\n",
    "# this helps to determine the threshold\n",
    "print('est_R_train')\n",
    "test_print(est_R_train)\n",
    "print('est_N_train')\n",
    "test_print(est_N_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elect avaliable ransomware sequence\n",
    "# it can also gain available normal sequence if input container with changing position\n",
    "def elect_rns_seq(rns_seq_cnt, nrm_seq_cnt, threshold = 0.0003):\n",
    "    res = dict()\n",
    "    for r in rns_seq_cnt:\n",
    "        if r not in nrm_seq_cnt and rns_seq_cnt[r] > threshold:\n",
    "            res[r] = rns_seq_cnt[r]\n",
    "        elif r in nrm_seq_cnt and rns_seq_cnt[r] > nrm_seq_cnt[r] + threshold:\n",
    "            res[r] = rns_seq_cnt[r]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat available ransomware code sequence and normal code sequence\n",
    "def gen_features(elected_seq1, elected_seq2):\n",
    "    features = list(elected_seq1.keys()) + list(elected_seq2.keys()) # len(featurs) is len(seq1) + len(seq2)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate vector with analyzed files into features\n",
    "def gen_vector_file(analyzed_file_list, features):\n",
    "    D = len(features)\n",
    "    N = len(analyzed_file_list)\n",
    "    Xs = []\n",
    "    for i in analyzed_file_list:\n",
    "        X = []\n",
    "        ith_sqs = analyzed_file_list[i]\n",
    "        for j in features:\n",
    "            if j in ith_sqs:\n",
    "                X.append(ith_sqs[j])\n",
    "            else:\n",
    "                X.append(0.0)\n",
    "        X = np.array(X)\n",
    "        Xs.append(X)\n",
    "    Xs = np.array(Xs)\n",
    "    return Xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure the accuracy of test files with generated vectors and SVM\n",
    "def model_svm_accuracy(R_train_sq, R_test_sq, N_train_sq, N_test_sq, threshold = 0.0003, print_op = False):\n",
    "    # available ransomware sequences and normal sequences\n",
    "    avl_R_sq = elect_rns_seq(est_R_train, est_N_train, threshold = threshold)\n",
    "    #avl_N_sq = dict()\n",
    "    avl_N_sq = elect_rns_seq(est_N_train, est_R_train, threshold = threshold)\n",
    "    \n",
    "    if print_op:\n",
    "        print('avl_R_sq' + ' number of sequences:' + str(len(avl_R_sq)))\n",
    "        # test_print(avl_R_sq)\n",
    "        print('avl_N_sq' + ' number of sequences:' + str(len(avl_N_sq)))\n",
    "        # test_print(avl_N_sq)\n",
    "    \n",
    "    features = gen_features(avl_R_sq, avl_N_sq)\n",
    "    # features = gen_features(avl_R_sq, dict())\n",
    "    \n",
    "    # generate train vectors with features estimated\n",
    "    # features mean the secquences of the values to compare\n",
    "    RX_train = gen_vector_file(R_train_sq, features)\n",
    "    RX_test = gen_vector_file(R_test_sq, features)\n",
    "    NX_train = gen_vector_file(N_train_sq, features)\n",
    "    NX_test = gen_vector_file(N_test_sq, features)\n",
    "    \n",
    "    yR_train = np.zeros(RX_train.shape[0])\n",
    "    yR_test = np.zeros(RX_test.shape[0])\n",
    "    yN_train = np.ones(NX_train.shape[0])\n",
    "    yN_test = np.ones(NX_test.shape[0])\n",
    "    \n",
    "    if print_op:\n",
    "        # check vectors' shape\n",
    "        print('RX_train\\'s shape:' + str(RX_train.shape) + ', yR_train:' + str(yR_train.shape))\n",
    "        print('NX_train\\'s shape:' + str(NX_train.shape) + ', yNtrain:' + str(yN_train.shape))\n",
    "        print('')\n",
    "    \n",
    "    # use Support Vector Machine\n",
    "    clf = svm.SVC()\n",
    "    train_set = RX_train.tolist() + NX_train.tolist()\n",
    "    y_train = yR_train.tolist() + yN_train.tolist()\n",
    "    clf.fit(train_set, y_train)\n",
    "    \n",
    "    # predict and measure the accuracy\n",
    "    pred_R = clf.score(RX_test, yR_test)\n",
    "    pred_N = clf.score(NX_test, yN_test)\n",
    "\n",
    "    print('accuracy of ransomware and normal files')\n",
    "    print('R:' + str(pred_R) + '\\nN:' + str(pred_N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split sequence list as training list and test list\n",
    "def tt_split(sq_list, train_list, test_list):\n",
    "    train_ = dict()\n",
    "    test_ = dict()\n",
    "    for i in train_list:\n",
    "        train_[i] = sq_list[i]\n",
    "    for i in test_list:\n",
    "        test_[i] = sq_list[i]\n",
    "    return train_, test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make train-test set with split size of files and shuffle random seed\n",
    "def gen_tt_set(est_R_train, est_N_train, files0, files1, R_sq, N_sq, test_sz = 0.33, rand_st = 42):\n",
    "    R_train, R_test = train_test_split(files0, test_size = test_sz, random_state = rand_st)\n",
    "    N_train, N_test = train_test_split(files1, test_size = test_sz, random_state = rand_st)\n",
    "    \n",
    "    # split with each cases\n",
    "    R_train_sq, R_test_sq = tt_split(R_sq, R_train, R_test)\n",
    "    N_train_sq, N_test_sq = tt_split(N_sq, N_train, N_test)\n",
    "    \n",
    "    return R_train_sq, R_test_sq, N_train_sq, N_test_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate pre factors\n",
    "tst_sz_list = [0.33, 0.5, 0.66]\n",
    "rnd_st_list = [7, 24, 42]\n",
    "\n",
    "tt_sets = []\n",
    "for ts in tst_sz_list:\n",
    "    for rs in rnd_st_list:\n",
    "        R_train_sq, R_test_sq, N_train_sq, N_test_sq = gen_tt_set(est_R_train, est_N_train, files0, files1, R_sq, N_sq, test_sz = ts, rand_st = rs)\n",
    "        tt_sets.append((R_train_sq, R_test_sq, N_train_sq, N_test_sq, ts, rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling and test\n",
    "th_list = [0.0001, 0.0003, 0.0005]\n",
    "\n",
    "# several test\n",
    "for th in th_list:\n",
    "    for i in range(len(tt_sets)):\n",
    "        model_svm_accuracy(tt_sets[i][0], tt_sets[i][1], tt_sets[i][2], tt_sets[i][3], threshold = th, print_op = True)\n",
    "        print('th:'+str(th)+', test_sz:'+str(tt_sets[i][4])+', rand_st:'+str(tt_sets[i][5]))\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
